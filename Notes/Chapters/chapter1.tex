\chapter{Oversikt fra foiler}
	

	%------ UKE 2 -----------

	\section{Foil 2.0 - 2.2: Introduction}
		\begin{itemize}
			\item Main theme:
				\begin{itemize}
					\item Requirements without tests will be ignored
					\item Tests without requirements are meaningless
				\end{itemize}
			\item What is a requirement?
			\item Challenges in requirement engineering
			\item Phenomena (world/shared/machine)
			\item Requirement statements
				\begin{itemize}
					\item Descriptive
					\item Predictive
				\end{itemize}
			\item Formulation of requirements
			\item Domain property
			\item Goal
				\begin{itemize}
					\item What is a goal?
					\item High-level Goal
					\item Requirement
					\item Assumption (expectation, responsability)
				\end{itemize}
			\item Goal statement typolology
			\item Goal categorization
			\item Functional vs non-functional goals
			\item Goal refinement tree
			\item Where do we get goals from?
			\item Qualitative goal-requirements tracing
			\item Qualitative metrics:
				\begin{itemize}
					\item Ambiguous, inconsistent, opaque, noisy, inncomplete, forward referencing
				\end{itemize}
			\item Ontology
		\end{itemize}


	%------ UKE 3 -----------

	\section{Foil 3.1: Guided Natual Language (GNL) and Requirement Boilerplates }
		\begin{itemize}
			\item Level of requirements
				\begin{itemize}
					\item Informal
					\item Semiformal
					\item Formal
				\end{itemize}
			\item Requirement elicitation (step1 - step 4)
			\item Challenges with requirement elicitation
			\item Humans and machines
			\item GNL and BP
		\end{itemize}

	\section{Foil 3.2: Requirements Traceability}
		\begin{itemize}
			\item What is requirement traceability?
			\item Traceability goals (Validation, verification, system inspection and certification/audits)
			\item Challenges of traceability
			\item Traceability metamodels
			\item Approaches to traceability
				\begin{itemize}
					\item Manual trace links
					\item Scenario driven traceability	
					\item Trace by tagging
				\end{itemize}
			\item Footprints	
		\end{itemize}

	\section{Foil 3.3: Requirements Testability}

		\begin{itemize}
			\item Testability definition
			\item Testability concerns
				\begin{itemize}
					\item How easy is it to test the implementation?
					\item How test-friendly is the requirements?
				\end{itemize}
			\item Three ways to check that we have achived our goals:
				\begin{itemize}
					\item Executing tests
					\item Run Experiments
					\item Inspect code
				\end{itemize}
			\item When do we use what? (test, experiments, inspections)
			\item Testability challenges
			\item Making requirements testable
			\item Requirementss for testability (The "what" and the "why")
			\item A testable requirement need to be:	
				\begin{itemize}
					\item Correct
					\item Complete
					\item Consistent
					\item Clear
					\item Relevant
					\item Feasible
					\item Traceable
				\end{itemize}
			\item Some sound advice:
				\begin{itemize}
					\item Modifying Phrases
					\item Vague words
					\item Pronouns with no reference
					\item Passive voice
					\item Negative requirements
					\item Assumptions and comparisasions
				\end{itemize}
			\item Concerns releated to implementation and testability:
				\begin{itemize}
					\item Autonomy of the system under test
					\item Observability of the testing progress
					\item Re-test efficiency
					\item Test restartability
				\end{itemize}
		\end{itemize}


	%------ UKE 5 -----------

	\section{Foil 5.1: Test vs. Inspection - Part 1}

		\begin{itemize}
			\item Man vs. machine
			\item Types of inspection:
				\begin{itemize}
					\item Walkthrough process
					\item The informal inspection process
					\item The formal inspection process
						\begin{itemize}
							\item Planning
							\item Kickoff
							\item Improve the product
							\item Checking changes
							\item Individual checking
							\item Logging Meeting
						\end{itemize}
				\end{itemize}
			\item Testing process
			\item Testing types
				\begin{itemize}
					\item Unit testing
					\item Function verification testing
					\item System verification testing
				\end{itemize}
			\item Strong and week points
			\begin{itemize}
				\item Testing 
				\item Inspections
			\end{itemize}
		\end{itemize}

	\section{Foil 5.2: Test vs. Inspection - Part 2}

		\begin{itemize}
			\item Defect types
			\item Triggers
			\item Inspection
				\begin{itemize}
					\item Defect types
					\item Triggers
				\end{itemize}
			\item Testing
				\begin{itemize}
					\item Defect types
					\item Triggers
				\end{itemize}
			\item Inspection as a social process
				\begin{itemize}
					\item Gain and loss
					\item Nominal group vs. Real group
				\end{itemize}
		\end{itemize}

	\section{Foil 5.3: Testing and Cost/Benefit}
		\begin{itemize}
			\item Why cost/benefit?
			\item When should we stop testing?
			\item Which cost should be included?
			\item Which benefits should be included?
			\item Hard costs and "soft benefits"
				\begin{itemize}		
				 	\item Cost are now
				 	\item Benefits are often later 
				 \end{itemize}
			\item How to assign value to "soft benefits"?
			\item Creation of value
			\item Soft benefits
			\item Cost/benefits are used to decide when to stop testing:
				\begin{itemize}
					\item P(Wrong): the probability of making the wrong decision
					\item Cost(Wrong): the cost of making the wrong decision
				\end{itemize}
			\item Risk = P(wrong) * Cost(wrong)
			\item The value of information
			\item Regret - pay now or maybe later?
			\item Leverage, risk and regret: 
				\begin{itemize}
					\item Total benefit = regret + benefit
					\item Total cost = risk + cost
					\item Leverage = (total benefit - total cost)/total cost
				\end{itemize}
		\end{itemize}


	%------ UKE 6 -----------

	\section{Foil 6.1: Writing a Test Strategy}
		\begin{itemize}
			\item Strategy vs. plan
				\begin{itemize}	
					\item {\it A plan says "Here are the steps", while a strategy says
					"here are the best steps".} The strategy speaks to the {\bf reason why},
					while the plan is {\bf focused on how}.
				\end{itemize}	
			\item Why a testing strategy
			\item Testing strategy concepts
				\begin{itemize}
					\item Purpose of a test strategy
					\item Testing focus (Users, analysts, designer, programmer)
					\item Contents of a testing strategy
						\begin{itemize}
							\item Project plan, risks and activities
							\item Relevant regulations
							\item Required process and standards
							\item Supporting guidelines
							\item Stakeholders
							\item Necessary resources
							\item Test levels and phases
								\begin{itemize}
									\item Development requriements level
									\item Design level
									\item Implementation level
									\item Test level
								\end{itemize}
							\item Completion criteria for each phase
							\item Required documentation and review method for each document
						\end{itemize}
					\item Software integrity levels (IEE and ISO standards)
					\item Test objectives and priorities
					\item Test data selection
					\item Random testing
					\item Domain partition testing
					\item Risk based testing
					\item User profile testing
					\item Bach's risk-based testing
				\end{itemize}
		\end{itemize}

	\section{Foil 6.2: White Box and Black Box Testing}
		\begin{itemize}
			\item What is white box testing?
			\item Code coverage
			\item Path coverage
			\item Error messages
			\item What is black box testing?
			\item Testing real-time systems
			\item Basic scenario pattern (BSP)
			\item Key-event service pattern (KSP)
			\item Test Automation
			\item White box testing
				\begin{itemize}
					\item Static white box testing (Code inspection and walkthrough)
					\item Dynamic white box testing (Statement coverage, path coverage, decision coverage
					use coverage).
				\end{itemize}
		\end{itemize}

	\section{Foil 6.3: Grey Box Testing and Mutation Testing}
		\begin{itemize}
			\item What is grey box testing?
			\item State based testing
			\item Round-trip path tree
			\item Mutation testing
				\begin{itemize}
					\item Type 1 (change random part of code)
					\item Type 2 (change random part of input)
				\end{itemize}
			\item Mutant testing strategies
				\begin{itemize}
					\item First order strategy
					\item Second order strategy
						\begin{itemize}
							\item Random mix
							\item First2Last
							\item Same Node
							\item Same Unit
							\item DiffOp
						\end{itemize}
				\end{itemize}
			\item Effectiveness measures: test and cost effectiveness
		\end{itemize}


	%------ UKE 8 -----------

	\section{Foil 8.1: Test Prioritation (Risk based)}
		\begin{itemize}
			\item How to prioritize ? (based on risk!)
			\item Risk-based testing
			\item Risk and stakeholders
			\item Stakeholders
			\item Risk identification
			\item Risk identification from use cases
			\item Consequence table
			\item Risk assessment
			\item Qualitative risk assessment
				\begin{itemize}
					\item Qualitative risk assessment
						\begin{itemize}
							\item Probability/consequence matrix
							\item The GALE method
						\end{itemize}
					\item Qualitative risk assessment based on CORAS model
				\end{itemize}
			\item Qualitative assessment
				\begin{itemize}
					\item Categories (project size, company turn over, company profit)
					\item Numbers 
				\end{itemize}
			\item Consequence and probability
			\item Risk and consequences
			\item The GALE method
			\item The GALE risk index
				\begin{itemize}
					\item Frequency score, $F_{E}$
					\item Probability score, $P_{E}$
					\item Severity score, S
					\item Risk Index I = $F_{E}$ + $P_{E}$ + S
				\end{itemize}
			\item The CORAS model
			\item The CORAS consequence table
			\item The CORAS frequency table
			\item CORAS example
			\item Worry list
			\item Testing and resources
			\item Risk- based testing Example
		\end{itemize}

	\section{Foil 8.2: Requirements Handling}
		\begin{itemize}
			\item Criteria for good requirement handling
			\item Viewpoints, perspectives and views
			\item Two classes of viewpoint:
				\begin{itemize}
					\item Direct viewpoint
					\item Indirect viewpoint
				\end{itemize}
			\item Types of viewpoint
				\begin{itemize}
					\item Data sources or sinks
					\item Representation frameworks
					\item Receivers of services
				\end{itemize}
			\item Viewpoint
			\item The VORD method
				\begin{itemize}
					\item Viewpoint identification
					\item Viewpoint structuring
					\item Viewpoint documentation
					\item Viewpoint-system mapping
				\end{itemize}
			\item VORD Example
			\item Advantages of viewpoint-oriented approaches in requirements handling
			\item Non-functional goals and soft goals
			\item Non-functional requirements Framework
			\item Cross-cutting requirements
			\item Requirements for COTS
			\item Requirements for outsourcing

		\end{itemize}


	%------ UKE 9 -----------

	\section{Foil 9.1: COTS testing}
		\begin{itemize}
			\item Approaches:
				\begin{itemize}
					\item Component meta-data approach
						\begin{itemize}
							\item What is meta-data?
							\item Assessment based on meta-data
						\end{itemize}
					\item Retro-components approach
						\begin{itemize}
							\item Retrospectors
						\end{itemize}
					\item Built-in test (BIT) approach
						\begin{itemize}
							\item BIT architecture
							\item BIT dead-lock testing
						\end{itemize}
					\item STECC strategy
					\item COTS
						\begin{itemize}
							\item Assessing COTS
						\end{itemize}
				\end{itemize}
			\item Black-box testing reducing usin Input-output analysis
			\item Test reduction using orthogonal array testing
		\end{itemize}

	\section{Foil 9.2: Outsourcing, subcontracting and COTS}
		\begin{itemize}
			\item Responsability
			\item Testing and confidence
			\item A product trustworthiness pattern
			\item Means to create product trust
			\item A process trustwothiness pattern
			\item Means to create process trust
			\item Testing and outsourcing
			\item Outsourcing requirements
			\item Trust in the component
			\item Testing COTS
				\begin{itemize}
					\item Internal robustness testing
						\begin{itemize}
							\item Why do we need a wrapper?
							\item What is a wrapper?
							\item Fault injection
						\end{itemize}
					\item External robustness testing
						\begin{itemize}
							\item Easy-to-understand message
						\end{itemize}
				\end{itemize}
		\end{itemize}

	%------ UKE 10 -----------


	\section{Foil 10.1: Domain Testing}
		\begin{itemize}
			\item Predicates
			\item Path conditions
			\item Path domains
				\begin{itemize}
					\item Open
					\item Closed
				\end{itemize}
			\item Domain error
			\item ON/OFF points
			\item Example: two dimensional space
			\item The problem of size and precision
			\item A simpllyfied strategy
			\item Effektiveness
			\item Code containing array references
			\item Non-linear borders
			\item Simple algorithm
			\item The use of domain testing
		\end{itemize}

	\section{Foil 10.2: Path selection criteria}
		\begin{itemize}
			\item Data flow testing
			\item Define (d-use), Use (u-use), Kill (k-use) (duk)
			\item Dynamic data flow testing Test strategy
				\begin{itemize}
					\item All definitions (AD)
					\item All predicate-uses (APU)
					\item All computational uses (ACU)
					\item All p-use/some c-use (APU + C)
					\item All c-use/some p-uses (ACU + P)
					\item All uses (AU)
					\item All du paths (ADUP)
				\end{itemize}
			\item Relationships between strategies
			\item Use of test coverage measures
				\begin{itemize}
					\item model
					\item Coverage measures considered
						\begin{itemize}
							\item Statement coverage
							\item Branch coverage
							\item LCSAJ
						\end{itemize}
					\item Equation summary
					\item Usage patterns
					\item Extended model
					\item Bishop's coverage model
					\item A limit result (MTTF)
				\end{itemize}
		\end{itemize}

	\section{Foil 10.3: Test Coverage}
		\begin{itemize}
			\item What is test coverage?
			\item Coverage cateories:
				\begin{itemize}
					\item Program based coverage
						\begin{itemize}
							\item Statement coverage
							\item Branch coverage
							\item Basic path coverage
						\end{itemize}
					\item Specification based coverage
				\end{itemize}
			\item Finite applicability
			\item Use of test coverage
				\begin{itemize}
					\item Test acceptance criteria
					\item Avoid redundancy
				\end{itemize}
			\item Fault seeding
			\item Fault seeding and estimation
			\item Capture/recapture
			\item Output coverage
			\item Specification based coverage
			\item Quality factor estimation
			\item Basic assumptions
			\item Choice of models 
				\begin{itemize}
					\item Errors
					\item Coverage
					\item Parameters
					\item Final model
				\end{itemize}

		\end{itemize}


	%------ UKE 13 -----------

	\section{Foil 13.1: Agile requirements through user stories and scenarios}
		\begin{itemize}
			\item 
		\end{itemize}

	\section{Foil 13.2 - 13-3: Advanced Use cases}
		\begin{itemize}
				\item Advanced use cases vocabulary (Actor, use case, use case model)
				\item Finding actors
				\item Finding use cases
				\item Key points for use cases
				\item Reuse opportunity for use cases and relationships between use cases:
					\begin{itemize}
						\item Dependency
						\item Include
						\item Extends
						\item Generalize
					\end{itemize}
				\item Adding details
				\item From use case to sequence diagram
				\item Use case index
					\begin{itemize}
						\item Scope
						\item Complexity
						\item Status
						\item Priority
					\end{itemize}
				\item Use case diagrams: pros and cons
				\item Textual use case
					\begin{itemize}
						\item Use case number
						\item Application
						\item Use case name
						\item Use case description
						\item Primary actor
						\item Precondition
						\item Trigger
						\item Basic flow
						\item Alternative flow
					\end{itemize}
				\item Textual use case: pros and cons
				\item Mis-use cases
				\item Textual mis-use case
				\item Why mis-use case?
				\item Mis-use case: pros and cons
				\item Use case maps
				\item Use case Maps - path
		\end{itemize}


	%------ UKE 14 -----------


	\section{Foil 14.1-14.2: Test Driven Development (TDD)}
		\begin{itemize}
				\item Development and testing
				\item Why TDD
				\item Green field projects (the roots of TDD, start at "scratch"/clean slate)
				\item TDD operates with four pairs of strategies:
					\begin{itemize}
						\item What is a green field project?
						\item Details vs the "big picture"
						\item Uncertain territory vs. the familiar
						\item Highest value vs. "low-hanging fruits"
					\end{itemize}
				\item Essential TDD concepts:
					\begin{itemize}
						\item Fixtures
						\item Test doubles
						\item Guidelines for a testable design
						\item Unit test patterns 
							\begin{itemize}
								\item Assertion types: resulting state, guard, delta, custom, interaction
								\item Keep or throw away a unit test ?
							\end{itemize}
						\item Legacy code 
							\begin{itemize}
								\item Inflection points (test point)
								\item Test and change
							\end{itemize}
					\end{itemize}
				\item TDD Acceptance testing
					\begin{itemize}
						\item Pick a user story
						\item Write tests for the story
						\item Automate the tests
					\end{itemize}
			\end{itemize}
	
	\section{Foil 14.3: Random Testing}
		\begin{itemize}
			\item 
		\end{itemize}

	\section{Foil 14.4: The effect of experience on the use of TDD}
		\begin{itemize}
			\item 
		\end{itemize}

	

	%------ UKE 15 pensum ?????? -----------

	\section{Foil 15.1: Regression Testing}

	\section{Foil 15.2: FIrewalls for Regression Testing}

	\section{Foil 15.3: Non-functional Requirements}

	\section{Foil 15.4: Scenario Testing}